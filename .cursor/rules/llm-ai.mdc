# General LLM / AI Engineering Rules (Vendor-Portable, Trust-First)

These rules apply to ANY work involving LLMs, AI features, embeddings, RAG, summarization, classification, or model-based automation.

Product philosophy: correctness → trust → UX depth → analytics → AI.

---

## 0) Non-Negotiable Principles

- AI must NOT reduce correctness, security, or trust.
- AI is read-only by default unless explicitly approved.
- AI output must be grounded in real data; never invent facts.
- Prefer deterministic + explainable behavior over “creative” behavior.
- Vendor lock-in is forbidden: implementations must be portable across providers.

---

## 1) Architecture: Provider-Abstraction Required

### 1.1 Single internal interface
All model calls MUST go through an internal portability layer (e.g. `LLMService`).
App code MUST NOT call provider SDKs directly.

- Define stable internal types:
  - `LLMRequest` (model, messages, temperature, maxTokens, optional jsonSchema)
  - `LLMResponse` (text, optional json, usage, meta)

### 1.2 Provider adapters only inside LLM module
Provider SDKs must be imported ONLY in provider adapter files (e.g. `providers/openai`, `providers/anthropic`, `providers/ollama`).

No provider SDK imports in controllers, UI components, or business services.

### 1.3 Model registry + routing
Use a registry/router to resolve `model` → `provider adapter`.

- Default model selection must be config/env-driven (e.g. `LLM_DEFAULT_MODEL`)
- Adding a new model/provider must not require changes to consuming code.

---

## 2) Safety Defaults (Always On)

- AI endpoints/services MUST be feature-gated (disabled by default).
- Strict RBAC + tenant isolation is mandatory.
- AI must never:
  - mutate production data
  - trigger side-effects
  - auto-remediate
  - execute arbitrary code
  - run arbitrary SQL
- If side-effects are ever needed, they must be explicit, reviewed, and separately authorized.

---

## 3) Data Handling & Privacy

### 3.1 Never send secrets
Never send any of the following to a model provider:
- API keys, webhook secrets, passwords
- auth headers, session tokens, CSRF tokens
- private encryption keys, credentials
- raw cookies
- full PII unless explicitly required and approved

### 3.2 Minimize data
Send only the minimal fields required to answer the user’s question.
Prefer IDs + summaries over full payloads.

### 3.3 Redaction is required
If sensitive fields may be present, implement and test redaction/minimization before model calls.

---

## 4) Grounding & Non-Hallucination Requirements

- If AI output is based on internal data, it MUST cite the specific records used (IDs/time ranges).
- If the model is uncertain, it must say so and explain why (missing data, ambiguous evidence).
- Never fabricate:
  - timestamps
  - actors/users
  - status codes
  - event details
  - metrics
- AI output must not contradict the source data; if it does, treat as an error.

---

## 5) Observability & Auditability

Every AI call MUST produce structured logs (do NOT log secrets):
- requestId / correlationId
- tenant/orgId + userId
- model + provider
- token usage (if available)
- latency
- success/failure + error category

If AI outputs are stored/cached, store provenance:
- prompt template version
- retrieval query/time range
- source record IDs
- model/provider

---

## 6) Reliability & Failure Behavior

- All provider calls must have timeouts.
- Retry only on transient network failures (bounded retries).
- If provider fails:
  - return a safe error
  - do not block core workflows
- Silent fallback to another provider is NOT allowed unless explicitly configured.

---

## 7) UI/UX Rules for AI Features

- AI output must be clearly labeled “AI-generated”.
- AI output must be visually secondary to primary source-of-truth data.
- Users must have a direct path to inspect underlying data used for the answer.
- Do not add chatbot UI unless explicitly designed/approved.
- Provide loading/error states that do not break the normal UX.

---

## 8) Testing Requirements (Minimum Bar)

- Unit tests for:
  - redaction/minimization
  - provider adapters mapping request/response to internal types
  - registry/router selecting the correct provider/model
- Contract test for:
  - `LLMService.generate()` stable output shape
- Integration tests for:
  - AI endpoints respecting RBAC + tenant boundaries
  - grounding/provenance is present when required

Avoid “snapshotting random model text”; assert invariants and schemas.

---

## 9) Explicit Anti-Patterns (Do Not Do)

- ❌ Calling OpenAI/Anthropic/Ollama SDK directly in controllers/services/UI
- ❌ Hardcoding model names in random files
- ❌ Sending raw payloads by default
- ❌ Letting AI mutate data or trigger actions
- ❌ Storing AI output without provenance
- ❌ Silent multi-provider fallback without config

---

## 10) Deliverable Standard

Any AI-related PR must include:
- provider-agnostic interface + registry
- redaction/minimization
- timeouts + safe failure behavior
- structured logging
- tests meeting the minimum bar above
